{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning import pytorch as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "from chemprop import data, featurizers, models, nn\n",
    "pl.seed_everything(1)\n",
    "from utils import *\n",
    "# from data_utils import data_prep, prep_data, load_data, split_data, preprocess_data, create_data_loaders, create_mpnn_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>400</th>\n",
       "      <th>402</th>\n",
       "      <th>404</th>\n",
       "      <th>406</th>\n",
       "      <th>408</th>\n",
       "      <th>410</th>\n",
       "      <th>412</th>\n",
       "      <th>414</th>\n",
       "      <th>416</th>\n",
       "      <th>...</th>\n",
       "      <th>3982</th>\n",
       "      <th>3984</th>\n",
       "      <th>3986</th>\n",
       "      <th>3988</th>\n",
       "      <th>3990</th>\n",
       "      <th>3992</th>\n",
       "      <th>3994</th>\n",
       "      <th>3996</th>\n",
       "      <th>3998</th>\n",
       "      <th>4000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c...</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(O)CC(C)C#COC#CC(C)CC(C)O</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(B...</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(...</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85501</th>\n",
       "      <td>N#Cc1c(Br)[nH]c2c(O)cccc12</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85502</th>\n",
       "      <td>CC(=O)c1cnc2sc(C(=O)Nc3cc(NC(=O)c4cccc(C(C)(C)...</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85503</th>\n",
       "      <td>Cc1ccc(C=NNc2cc(C(F)(F)F)ccc2Cl)cc1</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85504</th>\n",
       "      <td>CN(C)Cc1c(C(=O)NC2N=C(c3ccccc3F)c3cccc4c3N(CC4...</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85505</th>\n",
       "      <td>Cc1ccc2oc(C(=O)Nc3ccccc3C)cc2n1</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85506 rows × 1802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  smiles       400       402  \\\n",
       "0      CN(c1ccc(NC(=O)Nc2ccccc2)cc1)S(=O)(=O)c1ccc(-c...  0.000771  0.000772   \n",
       "1                            CC(O)CC(C)C#COC#CC(C)CC(C)O  0.001267  0.001275   \n",
       "2      Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccc(OCC(C)C)c(B...  0.000540  0.000540   \n",
       "3      COC12C(COC(N)=O)C3=C(C(=O)C(C)=C(N)C3=O)N1CC1NC12  0.001041  0.001044   \n",
       "4      CC(C)(O)C(NC(=O)c1cnn2cc(C3CC3)cnc12)c1ccc(OC(...  0.000721  0.000727   \n",
       "...                                                  ...       ...       ...   \n",
       "85501                         N#Cc1c(Br)[nH]c2c(O)cccc12  0.001536  0.001529   \n",
       "85502  CC(=O)c1cnc2sc(C(=O)Nc3cc(NC(=O)c4cccc(C(C)(C)...  0.001173  0.001170   \n",
       "85503                Cc1ccc(C=NNc2cc(C(F)(F)F)ccc2Cl)cc1  0.000756  0.000757   \n",
       "85504  CN(C)Cc1c(C(=O)NC2N=C(c3ccccc3F)c3cccc4c3N(CC4...  0.001383  0.001370   \n",
       "85505                    Cc1ccc2oc(C(=O)Nc3ccccc3C)cc2n1  0.000442  0.000440   \n",
       "\n",
       "            404       406       408       410       412       414       416  \\\n",
       "0      0.000774  0.000785  0.000792  0.000797  0.000800  0.000809  0.000812   \n",
       "1      0.001275  0.001290  0.001292  0.001303  0.001306  0.001320  0.001335   \n",
       "2      0.000540  0.000541  0.000545  0.000547  0.000545  0.000545  0.000548   \n",
       "3      0.001044  0.001053  0.001056  0.001063  0.001061  0.001069  0.001074   \n",
       "4      0.000726  0.000733  0.000737  0.000743  0.000745  0.000748  0.000760   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "85501  0.001526  0.001542  0.001543  0.001550  0.001555  0.001582  0.001577   \n",
       "85502  0.001179  0.001178  0.001185  0.001190  0.001186  0.001191  0.001203   \n",
       "85503  0.000751  0.000758  0.000764  0.000762  0.000760  0.000759  0.000758   \n",
       "85504  0.001379  0.001362  0.001364  0.001355  0.001344  0.001336  0.001336   \n",
       "85505  0.000438  0.000437  0.000443  0.000442  0.000443  0.000446  0.000442   \n",
       "\n",
       "       ...      3982      3984      3986      3988      3990      3992  \\\n",
       "0      ...  0.000774  0.000786  0.000803  0.000780  0.000782  0.000776   \n",
       "1      ...  0.001032  0.001046  0.001065  0.001040  0.001047  0.001011   \n",
       "2      ...  0.000462  0.000465  0.000453  0.000481  0.000469  0.000452   \n",
       "3      ...  0.001045  0.001055  0.001057  0.001063  0.001051  0.001031   \n",
       "4      ...  0.000649  0.000653  0.000655  0.000656  0.000650  0.000636   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "85501  ...  0.000386  0.000379  0.000344  0.000405  0.000378  0.000348   \n",
       "85502  ...  0.000725  0.000735  0.000743  0.000736  0.000736  0.000719   \n",
       "85503  ...  0.000368  0.000365  0.000349  0.000381  0.000366  0.000352   \n",
       "85504  ...  0.000793  0.000801  0.000797  0.000811  0.000799  0.000788   \n",
       "85505  ...  0.000595  0.000606  0.000609  0.000608  0.000605  0.000586   \n",
       "\n",
       "           3994      3996      3998      4000  \n",
       "0      0.000770  0.000765  0.000764  0.000767  \n",
       "1      0.001003  0.001020  0.001040  0.000981  \n",
       "2      0.000458  0.000458  0.000465  0.000448  \n",
       "3      0.001030  0.001023  0.001026  0.001022  \n",
       "4      0.000633  0.000632  0.000635  0.000628  \n",
       "...         ...       ...       ...       ...  \n",
       "85501  0.000360  0.000366  0.000375  0.000352  \n",
       "85502  0.000718  0.000723  0.000732  0.000705  \n",
       "85503  0.000358  0.000356  0.000358  0.000354  \n",
       "85504  0.000790  0.000780  0.000778  0.000785  \n",
       "85505  0.000585  0.000584  0.000592  0.000575  \n",
       "\n",
       "[85506 rows x 1802 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = r\"C:\\Users\\rhys-\\OneDrive\\data_hnrs\\spectra\\mcgill\\computed_spectra.parquet\" # path to your data .csv file\n",
    "num_workers = 0 # number of workers for dataloader. 0 means using main process for data loading\n",
    "smiles_column = \"smiles\" # name of the column containing SMILES strings\n",
    "target_columns = np.arange(400,4002,2).astype(str) # list of names of the columns containing targets\n",
    "\n",
    "df_input = pd.read_parquet(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(df):\n",
    "    # Select the numerical columns (excluding the first column)\n",
    "    numerical_columns = df.columns[1:]\n",
    "    \n",
    "    # Find the maximum value in each row (excluding the first column)\n",
    "    max_values = df[numerical_columns].max(axis=1)\n",
    "    \n",
    "    # Divide each value in the numerical columns by the corresponding maximum value\n",
    "    df[numerical_columns] = df[numerical_columns].div(max_values, axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_input = normalize_rows(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_test_path = r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\data\\nist\\nist_test.parquet\"\n",
    "\n",
    "nist_test_df = pd.read_parquet(nist_test_path)\n",
    "\n",
    "test_datapoints = get_mol_datapoints(nist_test_df, smiles_column, target_columns)\n",
    "\n",
    "test_dset = data.MoleculeDataset(test_datapoints, featurizers.SimpleMoleculeMolGraphFeaturizer())\n",
    "\n",
    "test_loader = data.MolGraphDataLoader(test_dset, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rndm_loader(test_data):\n",
    "    featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "\n",
    "    test_dset = data.MoleculeDataset(test_data, featurizer)\n",
    "\n",
    "    return data.MolGraphDataLoader(test_dset, num_workers=0)\n",
    "\n",
    "# rndm_test_loader = create_rndm_loader(test_1[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = get_mol_datapoints(df_input, smiles_column, target_columns)\n",
    "\n",
    "train_idx, val_idx, test_idx = data.splitting.split_data(\n",
    "    datapoints,\n",
    "    num_folds=8,\n",
    "    split='cv',\n",
    ")\n",
    "\n",
    "train_1 = [datapoints[i] for i in train_idx[0]]\n",
    "val_1 = [datapoints[i] for i in val_idx[0]]\n",
    "test_1 = [datapoints[i] for i in test_idx[0]]\n",
    "\n",
    "train_2 = [datapoints[i] for i in train_idx[1]]\n",
    "val_2 = [datapoints[i] for i in val_idx[1]]\n",
    "test_2 = [datapoints[i] for i in test_idx[1]]\n",
    "\n",
    "train_3 = [datapoints[i] for i in train_idx[2]]\n",
    "val_3 = [datapoints[i] for i in val_idx[2]]\n",
    "test_3 = [datapoints[i] for i in test_idx[2]]\n",
    "\n",
    "train_4 = [datapoints[i] for i in train_idx[3]]\n",
    "val_4 = [datapoints[i] for i in val_idx[3]]\n",
    "test_4 = [datapoints[i] for i in test_idx[3]]\n",
    "\n",
    "train_5 = [datapoints[i] for i in train_idx[4]]\n",
    "val_5 = [datapoints[i] for i in val_idx[4]]\n",
    "test_5 = [datapoints[i] for i in test_idx[4]]\n",
    "\n",
    "train_6 = [datapoints[i] for i in train_idx[5]]\n",
    "val_6 = [datapoints[i] for i in val_idx[5]]\n",
    "test_6= [datapoints[i] for i in test_idx[5]]\n",
    "\n",
    "train_7 = [datapoints[i] for i in train_idx[6]]\n",
    "val_7 = [datapoints[i] for i in val_idx[6]]\n",
    "test_7 = [datapoints[i] for i in test_idx[6]]\n",
    "\n",
    "train_8 = [datapoints[i] for i in train_idx[7]]\n",
    "val_8 = [datapoints[i] for i in val_idx[7]]\n",
    "test_8 = [datapoints[i] for i in test_idx[7]]\n",
    "\n",
    "def create_data_loaders(train_data, val_data, test_data, num_workers=0):\n",
    "    featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "    train_dset = data.MoleculeDataset(train_data, featurizer)\n",
    "    val_dset = data.MoleculeDataset(val_data, featurizer)\n",
    "    test_dset = data.MoleculeDataset(test_data, featurizer)\n",
    "\n",
    "    train_loader = data.MolGraphDataLoader(train_dset, num_workers=num_workers)\n",
    "    val_loader = data.MolGraphDataLoader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "    test_loader = data.MolGraphDataLoader(test_dset, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader_1, val_loader_1, test_loader_1 = create_data_loaders(train_1, val_1, test_1, num_workers)\n",
    "train_loader_2, val_loader_2, test_loader_2 = create_data_loaders(train_2, val_2, test_2, num_workers)\n",
    "train_loader_3, val_loader_3, test_loader_3 = create_data_loaders(train_3, val_3, test_3, num_workers)\n",
    "train_loader_4, val_loader_4, test_loader_4 = create_data_loaders(train_4, val_4, test_4, num_workers)\n",
    "train_loader_5, val_loader_5, test_loader_5 = create_data_loaders(train_5, val_5, test_5, num_workers)\n",
    "train_loader_6, val_loader_6, test_loader_6 = create_data_loaders(train_6, val_6, test_6, num_workers)\n",
    "train_loader_7, val_loader_7, test_loader_7 = create_data_loaders(train_7, val_7, test_7, num_workers)\n",
    "train_loader_8, val_loader_8, test_loader_8 = create_data_loaders(train_8, val_8, test_8, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(metric: str, agg: str = 'mean'):\n",
    "    mp = nn.BondMessagePassing(\n",
    "    depth = 6,\n",
    "    d_h = 2200,\n",
    "    dropout=0.05,\n",
    "    # activation='SILU'\n",
    ")\n",
    "    if agg == 'mean':\n",
    "        agg = nn.MeanAggregation(\n",
    "\n",
    "        )\n",
    "\n",
    "    elif agg == 'attentive':\n",
    "        agg = nn.AttentiveAggregation(\n",
    "            output_size=2200,\n",
    "        )\n",
    "\n",
    "    elif agg == 'sum': \n",
    "        agg = nn.SumAggregation(\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Invalid aggregation: {agg}')\n",
    "\n",
    "    # agg = nn.AttentiveAggregation(\n",
    "    #     output_size=2200,\n",
    "    # )\n",
    "\n",
    "    ffn = nn.RegressionFFN(\n",
    "        input_dim=2200,\n",
    "        n_layers=6,\n",
    "        hidden_dim=2200,\n",
    "        dropout=0.05,\n",
    "        # activation='SILU',\n",
    "        # loc=scaler.mean_, # pass in the mean of the training targets\n",
    "        # scale=scaler.scale_,\n",
    "        n_tasks=1801 # pass in the scale of the training targets\n",
    "    )\n",
    "    batch_norm=False\n",
    "    if metric == 'rmse':\n",
    "        metric_list = [nn.RMSEMetric()]\n",
    "    elif metric == 'sid':\n",
    "        metric_list = [nn.SIDMetric(), nn.RMSEMetric()]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Invalid metric: {metric}')\n",
    "    return models.MPNN(mp, agg, ffn, batch_norm, metrics=metric_list)\n",
    "\n",
    "mpnn1 = create_model('rmse', 'attentive')\n",
    "mpnn2 = create_model('rmse', 'attentive')\n",
    "mpnn3 = create_model('rmse', 'attentive')\n",
    "mpnn4 = create_model('rmse', 'attentive')\n",
    "mpnn5 = create_model('rmse', 'attentive')\n",
    "mpnn6 = create_model('rmse', 'attentive')\n",
    "mpnn7 = create_model('rmse', 'attentive')\n",
    "mpnn8 = create_model('rmse', 'attentive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_1 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    "    # callbacks=[metric_tracker, early_stop_callback]\n",
    ")\n",
    "\n",
    "trainer_2 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    ")\n",
    "\n",
    "trainer_3 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    "    # callbacks=[metric_tracker, early_stop_callback]\n",
    ")\n",
    "\n",
    "trainer_4 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    ")\n",
    "\n",
    "trainer_5 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    "    # callbacks=[metric_tracker, early_stop_callback]\n",
    ")\n",
    "\n",
    "trainer_6 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    ")\n",
    "\n",
    "trainer_7 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    ")\n",
    "\n",
    "trainer_8 = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "c:\\Users\\rhys-\\miniconda3\\envs\\cp3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rhys-\\miniconda3\\envs\\cp3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:16<00:00, 16.87it/s, v_num=11, train/loss=0.00476, val_loss=0.0684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:16<00:00, 16.87it/s, v_num=11, train/loss=0.00476, val_loss=0.0684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:14<00:00, 17.12it/s, v_num=12, train/loss=0.00514, val_loss=0.0689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:14<00:00, 17.12it/s, v_num=12, train/loss=0.00514, val_loss=0.0689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:18<00:00, 16.41it/s, v_num=13, train/loss=0.00482, val_loss=0.0691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:18<00:00, 16.41it/s, v_num=13, train/loss=0.00482, val_loss=0.0691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:16<00:00, 16.78it/s, v_num=14, train/loss=0.0058, val_loss=0.0697] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:16<00:00, 16.78it/s, v_num=14, train/loss=0.0058, val_loss=0.0697]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:23<00:00, 15.37it/s, v_num=15, train/loss=0.00621, val_loss=0.0699]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:23<00:00, 15.37it/s, v_num=15, train/loss=0.00621, val_loss=0.0699]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:17<00:00, 16.63it/s, v_num=16, train/loss=0.00564, val_loss=0.0689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:17<00:00, 16.63it/s, v_num=16, train/loss=0.00564, val_loss=0.0689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:20<00:00, 16.02it/s, v_num=17, train/loss=0.00579, val_loss=0.0688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:20<00:00, 16.02it/s, v_num=17, train/loss=0.00579, val_loss=0.0688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing   | 10.3 M\n",
      "1 | agg             | AttentiveAggregation | 2.2 K \n",
      "2 | bn              | Identity             | 0     \n",
      "3 | predictor       | RegressionFFN        | 33.0 M\n",
      "  | other params    | n/a                  | 1.8 K \n",
      "---------------------------------------------------------\n",
      "43.3 M    Trainable params\n",
      "1.8 K     Non-trainable params\n",
      "43.3 M    Total params\n",
      "173.278   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:19<00:00, 16.08it/s, v_num=18, train/loss=0.00584, val_loss=0.0689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1283/1283 [01:19<00:00, 16.08it/s, v_num=18, train/loss=0.00584, val_loss=0.0689]\n"
     ]
    }
   ],
   "source": [
    "trainer_1.fit(mpnn1, train_loader_1, val_loader_1)\n",
    "trainer_2.fit(mpnn2, train_loader_2, val_loader_2)\n",
    "trainer_3.fit(mpnn3, train_loader_3, val_loader_3)\n",
    "trainer_4.fit(mpnn4, train_loader_4, val_loader_4)\n",
    "trainer_5.fit(mpnn5, train_loader_5, val_loader_5)\n",
    "trainer_6.fit(mpnn6, train_loader_6, val_loader_6)\n",
    "trainer_7.fit(mpnn7, train_loader_7, val_loader_7)\n",
    "trainer_8.fit(mpnn8, train_loader_8, val_loader_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop import models \n",
    "\n",
    "trainer_1.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn1.ckpt')\n",
    "trainer_2.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn2.ckpt')\n",
    "trainer_3.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn3.ckpt')\n",
    "trainer_4.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn4.ckpt')\n",
    "trainer_5.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn5.ckpt')\n",
    "trainer_6.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn6.ckpt')\n",
    "trainer_7.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn7.ckpt')\n",
    "trainer_8.save_checkpoint(r'C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn8.ckpt')\n",
    "\n",
    "checkpoint = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn1.ckpt\")\n",
    "checkpoint2 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn2.ckpt\")\n",
    "checkpoint3 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn3.ckpt\")\n",
    "checkpoint4 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn4.ckpt\")\n",
    "checkpoint5 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn5.ckpt\")\n",
    "checkpoint6 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn6.ckpt\")\n",
    "checkpoint7 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn7.ckpt\")\n",
    "checkpoint8 = torch.load(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_mpnn8.ckpt\")\n",
    "\n",
    "# Assuming 'output_size' needs to be added or corrected\n",
    "# You need to know the correct value for 'output_size'\n",
    "checkpoint['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint2['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint3['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint4['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint5['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint6['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint7['hyper_parameters']['agg']['output_size'] = 2200\n",
    "checkpoint8['hyper_parameters']['agg']['output_size'] = 2200\n",
    "\n",
    "torch.save(checkpoint, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_1.ckpt\")\n",
    "torch.save(checkpoint2, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_2.ckpt\")\n",
    "torch.save(checkpoint3, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_3.ckpt\")\n",
    "torch.save(checkpoint4, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_4.ckpt\")\n",
    "torch.save(checkpoint5, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_5.ckpt\")\n",
    "torch.save(checkpoint6, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_6.ckpt\")\n",
    "torch.save(checkpoint7, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_7.ckpt\")\n",
    "torch.save(checkpoint8, r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_8.ckpt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = models.MPNN.load_from_checkpoint(r\"C:\\Users\\rhys-\\OneDrive\\Documents\\Github\\thesis_results\\models\\xtb_modified_mpnn_1.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\rhys-\\miniconda3\\envs\\cp3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 214/214 [00:10<00:00, 19.89it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/rmse           0.06847275793552399\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/rmse': 0.06847275793552399}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_loaded = pl.Trainer(\n",
    "    precision='bf16-mixed',\n",
    "    logger=True,\n",
    "    enable_checkpointing=False, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=6, # number of epochs to train for\n",
    "    # callbacks=[metric_tracker, early_stop_callback]\n",
    ")\n",
    "\n",
    "trainer_loaded.test(loaded_model, test_loader_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
